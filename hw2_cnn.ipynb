{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from nltk import ngrams\n",
    "import string\n",
    "import re\n",
    "import pickle as pkl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/ml5893/pyenv/py3.6.3/lib/python3.6/site-packages (3.3)\r\n",
      "Requirement already satisfied: six in /home/ml5893/pyenv/py3.6.3/lib/python3.6/site-packages (from nltk) (1.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = []\n",
    "with open('snli_val.tsv','r', encoding = 'utf-8', newline = '') as file:\n",
    "    tsvreader = csv.reader(file, delimiter='\\t')\n",
    "    data_val = [line for line in tsvreader]\n",
    "    \n",
    "data_train = []\n",
    "with open('snli_train.tsv','r', encoding = 'utf-8', newline = '') as file:\n",
    "    tsvreader = csv.reader(file, delimiter='\\t')\n",
    "    data_train = [line for line in tsvreader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 100001\n",
      "Validation dataset size is 1001\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size is {}\".format(len(data_train)))\n",
    "print(\"Validation dataset size is {}\".format(len(data_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_s1, data_val_s2, data_val_label = zip(*data_val)\n",
    "data_train_s1, data_train_s2, data_train_label = zip(*data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_s1 = data_val_s1[1:]\n",
    "data_val_s2 = data_val_s2[1:]\n",
    "data_val_label = data_val_label[1:]\n",
    "data_train_s1 = data_train_s1[1:]\n",
    "data_train_s2 = data_train_s2[1:]\n",
    "data_train_label = data_train_label[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tokenize data\n",
    "\"\"\"\n",
    "def tokenize_ngrams(sent):\n",
    "    #tokens = ngrams(re.findall(r\"[\\w']+|[.,!?;():~@+-<>#]\", sent.lower()),n)\n",
    "    tokens = ngrams([gram for gram in re.findall(r\"[\\w']+|[.,!?;():~@+-<>#]*\", sent.lower())\n",
    "                     if (gram not in string.punctuation)], 1)\n",
    "    return [token[0] for token in tokens]\n",
    "\n",
    "def tokenize_dataset_ngrams(dataset):\n",
    "    all_tokens = []\n",
    "    token_dataset = []\n",
    "    for sample in dataset:\n",
    "        tokens = tokenize_ngrams(sample)\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "    return token_dataset, all_tokens\n",
    "    \n",
    "def convert_labels(dataset_label):\n",
    "    \"\"\"Convert labels from number\n",
    "       entails  --> 1\n",
    "       contradiction --> -1\n",
    "       neural --> 0\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for l in dataset_label:\n",
    "        if l == 'entailment':\n",
    "            labels.append(2)\n",
    "        elif l == 'contradiction':\n",
    "            labels.append(0)\n",
    "        elif l == 'neutral':\n",
    "            labels.append(1)\n",
    "        elif l=='label':\n",
    "            labels.append('label')\n",
    "    return labels\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_s1_tokens, _ = tokenize_dataset_ngrams(data_val_s1)\n",
    "data_val_s2_tokens, _ = tokenize_dataset_ngrams(data_val_s2)\n",
    "data_val_label0 = convert_labels(data_val_label)\n",
    "data_train_s1_tokens, all_train_s1_tokens = tokenize_dataset_ngrams(data_train_s1)\n",
    "data_train_s2_tokens, all_train_s2_tokens = tokenize_dataset_ngrams(data_train_s2)\n",
    "data_train_label0 = convert_labels(data_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of all tokens in train dataset is 2037612\n"
     ]
    }
   ],
   "source": [
    "all_train_tokens = all_train_s1_tokens + all_train_s2_tokens\n",
    "print(\"Total number of all tokens in train dataset is {}\".format(len(all_train_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(data_val_label0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Build Vocabulary\"\"\"\n",
    "from collections import Counter\n",
    "\n",
    "max_vocab_size = 20000\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size-2))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "token2id, id2token = build_vocab(all_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(token2id)< max_vocab_size:\n",
    "    max_vocab_size = len(token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19581\n"
     ]
    }
   ],
   "source": [
    "print(len(token2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding_matrix shape is (200000, 300)\n",
      "Embedding Vocabualry size is 200000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load pretrained embedding matrix\"\"\"\n",
    "\n",
    "words_to_load = 200000\n",
    "\n",
    "with open('wiki-news-300d-1M.vec', 'r', encoding = 'utf-8') as f:\n",
    "    embedding_matrix = np.zeros([words_to_load, 300])\n",
    "    word2id_emb = {}\n",
    "    id2word_emb = []\n",
    "    next(f)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        id2word_emb.append(s[0])\n",
    "        word2id_emb[s[0]] = 0\n",
    "        embedding_matrix[i] = np.asarray(s[1:])\n",
    "\n",
    "print(\"Embedding_matrix shape is {}\".format(embedding_matrix.shape))\n",
    "print(\"Embedding Vocabualry size is {}\".format(len(id2word_emb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8282008069046525 tokens appear in the pretrained dataset\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Build pretrained Embedding Matrix\"\"\"\n",
    "pre_emb_matrix = np.zeros([max_vocab_size, 300])\n",
    "\n",
    "i = 0\n",
    "for word in id2token:\n",
    "    try:\n",
    "        id_pretrain = word2id_emb[word]\n",
    "        pre_emb_matrix[token2id[word]] = embedding_matrix[id_pretrain]\n",
    "    except KeyError:\n",
    "        pre_emb_matrix[token2id[word]] = np.zeros(300)\n",
    "        i = i+1\n",
    "print(\"{} tokens appear in the pretrained dataset\".format(1-i/max_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19581, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_emb_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data, token2id):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_s1_indices = token2index_dataset(data_val_s1_tokens, token2id)\n",
    "data_val_s2_indices = token2index_dataset(data_val_s2_tokens, token2id)\n",
    "data_train_s1_indices = token2index_dataset(data_train_s1_tokens, token2id)\n",
    "data_train_s2_indices = token2index_dataset(data_train_s2_tokens, token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100000, 100000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_val_s1_indices), len(data_train_s2_indices), len(data_train_label0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_list_s1, data_list_s2, data_label_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of character\n",
    "        @param target_list: list of targets\n",
    "\n",
    "        \"\"\"\n",
    "        self.s1_list, self.s2_list, self.label_list = data_list_s1, data_list_s2, data_label_list\n",
    "        assert ((len(self.s1_list) == len(self.label_list)) and (len(self.s1_list) == len(self.s2_list)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        return [self.s1_list[key], self.s2_list[key], max(len(self.s1_list[key]), len(self.s2_list[key])), self.label_list[key]]\n",
    "\n",
    "def vocab_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    s1_list = []\n",
    "    s2_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[3])\n",
    "        length_list.append(datum[2])\n",
    "    # padding\n",
    "    #MAX_WORD_LENGTH\n",
    "    max_length = max(length_list)\n",
    "    for datum in batch:\n",
    "        padded_vec_s1 = np.pad(np.array(datum[0]),\n",
    "                                pad_width=((0,max_length-len(datum[0]))),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        padded_vec_s2 = np.pad(np.array(datum[1]),\n",
    "                                pad_width=((0,max_length-len(datum[1]))),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        s1_list.append(padded_vec_s1)\n",
    "        s2_list.append(padded_vec_s2)\n",
    "    ind_dec_order = np.argsort(length_list)[::-1]\n",
    "    s1_list = np.array(s1_list)[ind_dec_order]\n",
    "    s2_list = np.array(s2_list)[ind_dec_order]\n",
    "    length_list = np.array(length_list)[ind_dec_order]\n",
    "    label_list = np.array(label_list)[ind_dec_order]\n",
    "    return [torch.from_numpy(np.array(s1_list)), torch.from_numpy(np.array(s2_list)), torch.LongTensor(length_list), torch.LongTensor(label_list)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SNLIDataset(data_train_s1_indices, data_train_s2_indices, data_train_label0)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = SNLIDataset(data_val_s1_indices, data_val_s2_indices, data_val_label0)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, num_layers, kernal_size, num_classes, vocab_size, pretrained_weight):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        linear_size1 = 20\n",
    "        padding_size = int((kernal_size-1)/2)\n",
    "        \n",
    "        self.num_layers, self.hidden_size, self.kernal_size = num_layers, hidden_size, kernal_size\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=PAD_IDX)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "    \n",
    "        self.conv1 = nn.Conv1d(emb_size, hidden_size, kernel_size=kernal_size, padding=padding_size)\n",
    "        self.conv2 = nn.Conv1d(hidden_size, hidden_size, kernel_size=kernal_size, padding=padding_size)\n",
    "\n",
    "        self.linear1 = nn.Linear(2*hidden_size, linear_size1)\n",
    "        self.linear2 = nn.Linear(linear_size1, num_classes)\n",
    "\n",
    "    def forward(self, s1, s2, lengths):\n",
    "        batch_size, seq_len = s1.size()\n",
    "\n",
    "        embed_s1 = self.embedding(s1)\n",
    "        embed_s2 = self.embedding(s2)\n",
    "        \n",
    "        hidden_s1 = self.conv1(embed_s1.transpose(1,2)).transpose(1,2)\n",
    "        hidden_s1 = F.relu(hidden_s1.contiguous().view(-1, hidden_s1.size(-1))).view(batch_size, seq_len, hidden_s1.size(-1))\n",
    "\n",
    "        hidden_s1 = self.conv2(hidden_s1.transpose(1,2)).transpose(1,2)\n",
    "        hidden_s1 = F.relu(hidden_s1.contiguous().view(-1, hidden_s1.size(-1))).view(batch_size, seq_len, hidden_s1.size(-1))\n",
    "\n",
    "        hidden_s1 = torch.sum(hidden_s1, dim=1)\n",
    "        \n",
    "        hidden_s2 = self.conv1(embed_s2.transpose(1,2)).transpose(1,2)\n",
    "        hidden_s2 = F.relu(hidden_s2.contiguous().view(-1, hidden_s2.size(-1))).view(batch_size, seq_len, hidden_s2.size(-1))\n",
    "\n",
    "        hidden_s2 = self.conv2(hidden_s2.transpose(1,2)).transpose(1,2)\n",
    "        hidden_s2 = F.relu(hidden_s2.contiguous().view(-1, hidden_s2.size(-1))).view(batch_size, seq_len, hidden_s2.size(-1))\n",
    "\n",
    "        hidden_s2 = torch.sum(hidden_s2, dim=1)\n",
    "        \n",
    "        hidden = torch.cat((hidden_s1, hidden_s2),-1)\n",
    "        \n",
    "        hidden = self.linear1(hidden)\n",
    "        hidden = F.relu(hidden)\n",
    "        \n",
    "        logits = self.linear2(hidden)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for s1, s2, lengths, labels in loader:\n",
    "        s1_batch, s2_batch, lengths_batch, label_batch = s1, s2, lengths, labels\n",
    "        outputs = F.softmax(model(s1_batch, s2_batch, lengths_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model2(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    criterion_test = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.eval()\n",
    "    for s1, s2, lengths, labels in loader:\n",
    "        s1_batch, s2_batch, lengths_batch, label_batch = s1.to(device), s2.to(device), lengths.to(device), labels.to(device)\n",
    "        probability = model(s1_batch, s2_batch, lengths_batch)\n",
    "        loss_test = float(criterion_test(probability, label_batch))\n",
    "        total_loss += loss_test\n",
    "        outputs = F.softmax(probability, dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "        total += label_batch.size(0)\n",
    "        correct += predicted.eq(label_batch.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total), total_loss/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('result/cnn_hs100_ks5.p',\n",
       " 'result/cnn_acc_hs100_ks5.pdf',\n",
       " 'result/model_cnn_hs100_ks5.pt')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HIDDEN_SIZE = 200\n",
    "Kernal_size = 3\n",
    "result_FILE = 'result/cnn_hs'+str(HIDDEN_SIZE) +'_ks' + str(Kernal_size) +'.p'\n",
    "figname = 'result/cnn_acc_hs'+str(HIDDEN_SIZE) +'_ks' + str(Kernal_size) +'.pdf'\n",
    "model_name = 'result/model_cnn_hs'+str(HIDDEN_SIZE) +'_ks' + str(Kernal_size) +'.pt'\n",
    "result_FILE, figname, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(emb_size = 300, hidden_size = HIDDEN_SIZE, num_layers=2, kernal_size = Kernal_size,\n",
    "            num_classes = 3, vocab_size = pre_emb_matrix.shape[0], pretrained_weight = pre_emb_matrix).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6078583\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [301/3125], Validation Acc: 47.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml5893/pyenv/py3.6.3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [601/3125], Validation Acc: 53.0\n",
      "Epoch: [1/10], Step: [901/3125], Validation Acc: 52.7\n",
      "Epoch: [1/10], Step: [1201/3125], Validation Acc: 58.0\n",
      "Epoch: [1/10], Step: [1501/3125], Validation Acc: 61.6\n",
      "Epoch: [1/10], Step: [1801/3125], Validation Acc: 62.9\n",
      "Epoch: [1/10], Step: [2101/3125], Validation Acc: 62.0\n",
      "Epoch: [1/10], Step: [2401/3125], Validation Acc: 62.8\n",
      "Epoch: [1/10], Step: [2701/3125], Validation Acc: 63.5\n",
      "Epoch: [1/10], Step: [3001/3125], Validation Acc: 64.5\n",
      "Epoch: [2/10], Step: [301/3125], Validation Acc: 64.1\n",
      "Epoch: [2/10], Step: [601/3125], Validation Acc: 65.1\n",
      "Epoch: [2/10], Step: [901/3125], Validation Acc: 63.4\n",
      "Epoch: [2/10], Step: [1201/3125], Validation Acc: 64.5\n",
      "Epoch: [2/10], Step: [1501/3125], Validation Acc: 63.2\n",
      "Epoch: [2/10], Step: [1801/3125], Validation Acc: 64.2\n",
      "Epoch: [2/10], Step: [2101/3125], Validation Acc: 63.8\n",
      "Epoch: [2/10], Step: [2401/3125], Validation Acc: 64.5\n",
      "Epoch: [2/10], Step: [2701/3125], Validation Acc: 65.7\n",
      "Epoch: [2/10], Step: [3001/3125], Validation Acc: 65.5\n",
      "Epoch: [3/10], Step: [301/3125], Validation Acc: 64.1\n",
      "Epoch: [3/10], Step: [601/3125], Validation Acc: 65.7\n",
      "Epoch: [3/10], Step: [901/3125], Validation Acc: 63.8\n",
      "Epoch: [3/10], Step: [1201/3125], Validation Acc: 64.1\n",
      "Epoch: [3/10], Step: [1501/3125], Validation Acc: 65.3\n",
      "Epoch: [3/10], Step: [1801/3125], Validation Acc: 65.9\n",
      "Epoch: [3/10], Step: [2101/3125], Validation Acc: 64.9\n",
      "Epoch: [3/10], Step: [2401/3125], Validation Acc: 65.9\n",
      "Epoch: [3/10], Step: [2701/3125], Validation Acc: 65.4\n",
      "Epoch: [3/10], Step: [3001/3125], Validation Acc: 65.2\n",
      "Epoch: [4/10], Step: [301/3125], Validation Acc: 65.2\n",
      "Epoch: [4/10], Step: [601/3125], Validation Acc: 66.3\n",
      "Epoch: [4/10], Step: [901/3125], Validation Acc: 65.1\n",
      "Epoch: [4/10], Step: [1201/3125], Validation Acc: 64.7\n",
      "Epoch: [4/10], Step: [1501/3125], Validation Acc: 65.2\n",
      "Epoch: [4/10], Step: [1801/3125], Validation Acc: 63.5\n",
      "Epoch: [4/10], Step: [2101/3125], Validation Acc: 66.1\n",
      "Epoch: [4/10], Step: [2401/3125], Validation Acc: 65.2\n",
      "Epoch: [4/10], Step: [2701/3125], Validation Acc: 66.1\n",
      "Epoch: [4/10], Step: [3001/3125], Validation Acc: 65.4\n",
      "Epoch: [5/10], Step: [301/3125], Validation Acc: 65.6\n",
      "Epoch: [5/10], Step: [601/3125], Validation Acc: 64.8\n",
      "Epoch: [5/10], Step: [901/3125], Validation Acc: 66.3\n",
      "Epoch: [5/10], Step: [1201/3125], Validation Acc: 65.4\n",
      "Epoch: [5/10], Step: [1501/3125], Validation Acc: 65.7\n",
      "Epoch: [5/10], Step: [1801/3125], Validation Acc: 65.0\n",
      "Epoch: [5/10], Step: [2101/3125], Validation Acc: 66.4\n",
      "Epoch: [5/10], Step: [2401/3125], Validation Acc: 66.4\n",
      "Epoch: [5/10], Step: [2701/3125], Validation Acc: 65.4\n",
      "Epoch: [5/10], Step: [3001/3125], Validation Acc: 66.1\n",
      "Epoch: [6/10], Step: [301/3125], Validation Acc: 65.0\n",
      "Epoch: [6/10], Step: [601/3125], Validation Acc: 65.6\n",
      "Epoch: [6/10], Step: [901/3125], Validation Acc: 65.1\n",
      "Epoch: [6/10], Step: [1201/3125], Validation Acc: 65.4\n",
      "Epoch: [6/10], Step: [1501/3125], Validation Acc: 64.7\n",
      "Epoch: [6/10], Step: [1801/3125], Validation Acc: 66.2\n",
      "Epoch: [6/10], Step: [2101/3125], Validation Acc: 66.0\n",
      "Epoch: [6/10], Step: [2401/3125], Validation Acc: 66.7\n",
      "Epoch: [6/10], Step: [2701/3125], Validation Acc: 66.6\n",
      "Epoch: [6/10], Step: [3001/3125], Validation Acc: 64.9\n",
      "Epoch: [7/10], Step: [301/3125], Validation Acc: 65.6\n",
      "Epoch: [7/10], Step: [601/3125], Validation Acc: 65.3\n",
      "Epoch: [7/10], Step: [901/3125], Validation Acc: 64.9\n",
      "Epoch: [7/10], Step: [1201/3125], Validation Acc: 64.3\n",
      "Epoch: [7/10], Step: [1501/3125], Validation Acc: 64.2\n",
      "Epoch: [7/10], Step: [1801/3125], Validation Acc: 65.4\n",
      "Epoch: [7/10], Step: [2101/3125], Validation Acc: 64.6\n",
      "Epoch: [7/10], Step: [2401/3125], Validation Acc: 62.9\n",
      "Epoch: [7/10], Step: [2701/3125], Validation Acc: 65.7\n",
      "Epoch: [7/10], Step: [3001/3125], Validation Acc: 66.3\n",
      "Epoch: [8/10], Step: [301/3125], Validation Acc: 64.5\n",
      "Epoch: [8/10], Step: [601/3125], Validation Acc: 64.5\n",
      "Epoch: [8/10], Step: [901/3125], Validation Acc: 62.8\n",
      "Epoch: [8/10], Step: [1201/3125], Validation Acc: 63.7\n",
      "Epoch: [8/10], Step: [1501/3125], Validation Acc: 63.3\n",
      "Epoch: [8/10], Step: [1801/3125], Validation Acc: 64.3\n",
      "Epoch: [8/10], Step: [2101/3125], Validation Acc: 64.3\n",
      "Epoch: [8/10], Step: [2401/3125], Validation Acc: 63.9\n",
      "Epoch: [8/10], Step: [2701/3125], Validation Acc: 64.8\n",
      "Epoch: [8/10], Step: [3001/3125], Validation Acc: 64.8\n",
      "Epoch: [9/10], Step: [301/3125], Validation Acc: 64.0\n",
      "Epoch: [9/10], Step: [601/3125], Validation Acc: 64.2\n",
      "Epoch: [9/10], Step: [901/3125], Validation Acc: 64.5\n",
      "Epoch: [9/10], Step: [1201/3125], Validation Acc: 64.5\n",
      "Epoch: [9/10], Step: [1501/3125], Validation Acc: 64.6\n",
      "Epoch: [9/10], Step: [1801/3125], Validation Acc: 64.0\n",
      "Epoch: [9/10], Step: [2101/3125], Validation Acc: 63.7\n",
      "Epoch: [9/10], Step: [2401/3125], Validation Acc: 63.0\n",
      "Epoch: [9/10], Step: [2701/3125], Validation Acc: 63.6\n",
      "Epoch: [9/10], Step: [3001/3125], Validation Acc: 63.6\n",
      "Epoch: [10/10], Step: [301/3125], Validation Acc: 62.2\n",
      "Epoch: [10/10], Step: [601/3125], Validation Acc: 62.8\n",
      "Epoch: [10/10], Step: [901/3125], Validation Acc: 63.8\n",
      "Epoch: [10/10], Step: [1201/3125], Validation Acc: 63.4\n",
      "Epoch: [10/10], Step: [1501/3125], Validation Acc: 61.7\n",
      "Epoch: [10/10], Step: [1801/3125], Validation Acc: 62.8\n",
      "Epoch: [10/10], Step: [2101/3125], Validation Acc: 62.8\n",
      "Epoch: [10/10], Step: [2401/3125], Validation Acc: 65.1\n",
      "Epoch: [10/10], Step: [2701/3125], Validation Acc: 61.7\n",
      "Epoch: [10/10], Step: [3001/3125], Validation Acc: 62.4\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-4\n",
    "num_epochs = 10 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "val_acc_record = []\n",
    "train_acc_record = []\n",
    "val_loss_record = []\n",
    "train_loss_record = []\n",
    "step_record = []\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (s1, s2, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(s1.to(device), s2.to(device), lengths.to(device))\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "        if i > 0 and i % 300 == 0:\n",
    "            # validate\n",
    "            val_acc, val_loss = test_model2(val_loader, model)\n",
    "            val_acc_record.append(val_acc)\n",
    "            val_loss_record.append(val_loss)\n",
    "            train_acc, train_loss = test_model2(train_loader, model)\n",
    "            train_acc_record.append(train_acc)\n",
    "            train_loss_record.append(train_loss)\n",
    "            step_record.append(i + epoch*total_step)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format(\n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "            if val_acc > best_val_acc:\n",
    "                with open(model_name, 'wb') as f:\n",
    "                    torch.save(model, f)\n",
    "                    best_val_loss = val_loss\n",
    "\n",
    "training_curve = zip(step_record, train_acc_record, train_loss_record, val_acc_record, val_loss_record)\n",
    "pkl.dump(training_curve, open(result_FILE, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_record = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i in range(3125):\n",
    "        if i>0 and i % 300 == 0:\n",
    "            step_record.append(i + epoch*total_step)\n",
    "len(step_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_curve = zip(step_record, train_acc_record, train_loss_record, val_acc_record, val_loss_record)\n",
    "pkl.dump(training_curve, open(result_FILE, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b2aea696780>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(step_record, train_acc_record, label = 'train accuracy')\n",
    "plt.plot(step_record, val_acc_record, label = 'train accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy vs Training Step\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.savefig(figname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_name, 'rb') as f:\n",
    "    best_model = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader0 = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=1,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  True label:  0   Predicted label:  2\n",
      "1  True label:  2   Predicted label:  2\n",
      "2  True label:  2   Predicted label:  2\n",
      "3  True label:  2   Predicted label:  0\n",
      "4  True label:  2   Predicted label:  0\n",
      "5  True label:  2   Predicted label:  0\n",
      "6  True label:  2   Predicted label:  0\n",
      "7  True label:  0   Predicted label:  0\n",
      "8  True label:  1   Predicted label:  2\n",
      "9  True label:  0   Predicted label:  2\n",
      "10  True label:  2   Predicted label:  2\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "for s1, s2, lengths, labels in val_loader0:\n",
    "    s1_batch, s2_batch, lengths_batch, label_batch = s1.to(device), s2.to(device), lengths.to(device), labels.to(device)\n",
    "    outputs = F.softmax(best_model(s1_batch, s2_batch, lengths_batch), dim=1)\n",
    "    predicted = outputs.max(1, keepdim=True)[1]\n",
    "    print(n, \" True label: \", labels.data.numpy()[0], \"  Predicted label: \", (predicted.data).to('cpu').numpy()[0][0])\n",
    "    n = n+1\n",
    "    if n>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorrect Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Three women on a stage , one wearing red shoes , black pants , and a gray shirt is sitting on a prop , another is sitting on the floor , and the third wearing a black shirt and pants is standing , as a gentleman in the back tunes an instrument .',\n",
       " 'There are two women standing on the stage',\n",
       " 'contradiction')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_s1[0], data_val_s2[0], data_val_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Four people sit on a subway two read books , one looks at a cellphone and is wearing knee high boots .',\n",
       " 'Multiple people are on a subway together , with each of them doing their own thing .',\n",
       " 'entailment')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_s1[3], data_val_s2[3], data_val_label[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A group of numbered participants walk down the street together .',\n",
       " 'Participants wait for the beginning of the walkathon .',\n",
       " 'neutral')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_s1[8], data_val_s2[8], data_val_label[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Four people sit on a subway two read books , one looks at a cellphone and is wearing knee high boots .',\n",
       " 'Multiple people are on a subway together , with each of them doing their own thing .',\n",
       " 'entailment')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_s1[1], data_val_s2[1], data_val_label[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bicycles stationed while a group of people socialize .',\n",
       " 'People get together near a stand of bicycles .',\n",
       " 'entailment')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_s1[2], data_val_s2[2], data_val_label[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Two women , one walking her dog the other pushing a stroller .',\n",
       " 'There is a snowstorm .',\n",
       " 'contradiction')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_s1[7], data_val_s2[7], data_val_label[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on MultiNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_train_tokens.p   hw2_rnn_1-Copy1.ipynb  pre_emb_matrix\r\n",
      "data_train_tokens.p  hw2_rnn_1.ipynb\t    result\r\n",
      "data_val_tokens.p    hw2_rnn_2.ipynb\t    snli_train.tsv\r\n",
      "hw2_cnn-Copy1.ipynb  mnli_train.tsv\t    snli_val.tsv\r\n",
      "hw2_cnn.ipynb\t     mnli_val.tsv\t    wiki-news-300d-1M.vec\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = []\n",
    "with open('mnli_val.tsv','r', encoding = 'utf-8', newline = '') as file:\n",
    "    tsvreader = csv.reader(file, delimiter='\\t')\n",
    "    data_test = [line for line in tsvreader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5001"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence1', 'sentence2', 'label', 'genre']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_head = data_test[0]\n",
    "data_test_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = data_test[1:]\n",
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'Not entirely , ' I snapped , harsher than intended .\",\n",
       " 'I spoke more harshly than I wanted to .',\n",
       " 'entailment',\n",
       " 'fiction']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_test, s2_test, label_test, genre = zip(*data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slate', 'travel', 'fiction', 'government', 'telephone']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_set = list(set(genre))\n",
    "genre_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = {'slate': [], 'travel': [], 'fiction': [], 'government': [], 'telephone': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_test)):\n",
    "    data_t[data_test[i][-1]].append(data_test[i][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_t['slate']) + len(data_t['travel']) + len(data_t['fiction']) +len(data_t['government']) +len(data_t['telephone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = {'slate': 0, 'travel': 0, 'fiction': 0, 'government': 0, 'telephone': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slate\n",
      "40.818363273453095\n",
      "travel\n",
      "45.11201629327902\n",
      "fiction\n",
      "40.904522613065325\n",
      "government\n",
      "42.224409448818896\n",
      "telephone\n",
      "43.38308457711443\n"
     ]
    }
   ],
   "source": [
    "for gen in genre_set:\n",
    "    print(gen)\n",
    "    \n",
    "    data_s1, data_s2, data_label = zip(*data_t[gen])\n",
    "    data_s1_tokens, _ = tokenize_dataset_ngrams(data_s1)\n",
    "    data_s2_tokens, _ = tokenize_dataset_ngrams(data_s2)\n",
    "    data_label0 = convert_labels(data_label)\n",
    "    \n",
    "    data_s1_indices = token2index_dataset(data_s1_tokens, token2id)\n",
    "    data_s2_indices = token2index_dataset(data_s2_tokens, token2id)\n",
    "    \n",
    "    test_dataset = SNLIDataset(data_s1_indices, data_s2_indices, data_label0)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "    test_acc, test_loss = test_model2(test_loader, best_model)\n",
    "    print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_s1_tokens, _ = tokenize_dataset_ngrams(data_val_s1)\n",
    "data_val_s2_tokens, _ = tokenize_dataset_ngrams(data_val_s2)\n",
    "data_val_label0 = convert_labels(data_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_s1_indices = token2index_dataset(data_val_s1_tokens, token2id)\n",
    "data_val_s2_indices = token2index_dataset(data_val_s2_tokens, token2id)\n",
    "data_train_s1_indices = token2index_dataset(data_train_s1_tokens, token2id)\n",
    "data_train_s2_indices = token2index_dataset(data_train_s2_tokens, token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SNLIDataset(data_val_s1_indices, data_val_s2_indices, data_val_label0)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
